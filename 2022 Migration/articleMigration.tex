\documentclass{elsarticle}
\usepackage{graphicx}
%\usepackage{multicol}
%\usepackage{footmisc}
\usepackage{amstext}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage[english]{babel}
%\usepackage[official,right]{eurosym}
\selectlanguage{english}
\hyphenation{ExecEngine}
\newtheorem{lemma}{Lemma}
\def\Events{{\mathit E}}
\begin{document}
\include{preambleMigrations}

\title{A Theory for Data Migration of Information Systems}
\author[ou,ordina]{Stef Joosten\fnref{fn1}}
\ead{stef.joosten@ou.nl}
\author[umn]{Sebastiaan Joosten\fnref{fn2}}
\address[ou]{Open Universiteit Nederland, Heerlen, the Netherlands}
\address[ordina]{Ordina NV, Nieuwegein, the Netherlands}
\address[umn]{University of Minnesota, Minneapolis, USA}
\fntext[fn1]{ORCID 0000-0001-8308-0189}
\fntext[fn2]{ORCID 0000-0002-6590-6220}

\begin{abstract}
	The Ampersand project has provided the theory and tools to generate semantic information systems from an algebraic specification.
	However, information systems in practice may change repeatedly after their maiden deployment.
	Changes that affect the data model typically result in a data migration.
	In such cases, simply regenerating the system is not enough because it would reset the database to its initial state (deleting all data gathered so far).
	Data migration aims at preserving the data as much as possible.
	Typically, migration involves transferring the old data to the new system while preserving the semantics as much as possible.

	In this contribution we develop a theory for reliable data migration that aims at automating it as much as possible,
	to enable more frequent migrations.
	The ultimate target is to generate a migration from two specifications: the as-is specification and the to-be specification.
	A software generator that embodies this theory is subject of future research.
\end{abstract}

\begin{keyword}
relation algebra\sep software development\sep data migration\sep software migration\sep Ampersand
\end{keyword}
\maketitle

\section{Introduction}
\label{sct:Introduction}
	Data migration occurs when one stateful information system, $\infsys$, is replaced by another, $\infsys'$,
	while the data from $\infsys$ must be preserved.
	Agile teams today need to automate their data migrations, 
	as they do for all other activities in their software process.
	By continually automating their own work,
	teams keep improving their DevOps metrics such as deployment frequency, reliability of deployments, and change failure rate~\cite{DevOps2021}.

	Data migrations can produce headaches, however.
	The challenge of data migration is to preserve the meaning of data
	rather than just copy the data from one place to another.
	Accumulated data pollution can pose extra complications.
	This makes data migrations far from trivial and a potential impediment for rapid and reliable deployment.

	The benefits of automating data migrations work in two directions.
	The automation itself saves effort and errors,
	contributing to more frequent and smaller releases.
	Smaller and faster releases also mean smaller migrations
	and therefore a smaller difference between $\infsys$ and $\infsys'$.
	The smaller that difference, the simpler the migration and the more of it can be automated.

	A formal understanding of data migration will help to automate data migrations correctly and reliably.
	That is why this paper proposes a theory of migration that is based on the
	following premises:
\begin{itemize}
	\item the as-is data set may be polluted;
	\item the data migration may require human interaction, which may take time;
	\item the part of the data that does not change should be migrated automatically;
	\item the meaning of data must be preserved;
	\item the business must continu during the migration without interruption;
	\item the part of the migration that can be automated is usually not sufficient;
	      it takes additional human creativity to complete the migration specification.
\end{itemize}

	There have been other attempts to formalize data migration~\cite{Thalheim2013}.
	(At this point: Elaborate on earlier work)

\section{Migration steps}
	A smooth migration from an old system to a new system would go as follows:
	Launch the new system in parallel to the old, copy data from the old to the new system, and have everyone use the new system.
	However, numerous issues might impede that plan.
	The following examples illustrate the practical issues that may occur:
\begin{enumerate}
\item Data required in the new system is missing in the old system.
	There may be no way in the old system to enter that data.
	An example could be that every reimbursement form needs to have an address associated to it to mail the check to, but address information is not stored in the old system:
	The old system required the reimbursement office to look up employee's addresses from a hand-written list they had on their desk.
\item Data in the old system is wrong but cannot be corrected there due to how the old system was designed.
	An example is if the old system only allows approvals to be entered as the current user, and the CEO insists that her administrative staff enters his approvals into the system for her.
	This may result in approvals being entered as admin staff, where it was really the CEO making the approval.
\item Data in the old system does not satisfy invariants of the new system.
	There may be no way in the old system of making the data satisfy those invariants. We can use the same example as in the previous bullet point, but add the requirement (in the new system) that every purchase above a certain amount needs to be approved by the CEO.
\item A way of entering data into the old system is missing in the new system.
	People or automated processes might rely on these ways of entering data.
	An example could be that when employees turned their computers on or off, an ad-hoc script would automatically clock them in- and out to determine the number of hours they worked.
	A handful of employees still relies on this.
\item Data present in the old system cannot be stored in the new system.
	An example could be that references to physical locations where original receipts are kept are stored in the old system, but the new system relies on scans of receipts and allows the originals to be destroyed or not submitted.
	Until the original receipts are scanned, the old data should be kept.
\end{enumerate}

(@Bas, het volgende zit al in de oplossingen sfeer. Willen we dat hier al doen?)
	To mitigate these issues, we:
	
	\begin{enumerate}
	\item Allow `missing' triples requirements to be ignored during migration.
	\item Allow triples to be migrated while being marked as needing correction.
	\item Allow invariants in the new system to be ignored for certain triples during migration.
	\item Allow continued use of interfaces of the old system, data entered into the old system via those interfaces needs to be continuously copied to the new system.
	\item Retain data in the old system until it can be marked as ready to be phased out.
	\end{enumerate}	

\section{Terminology}
\label{sct:Terminology}
	To migrate data from one information system to another,
	we must define ``information system''.
	In that definition we will single out the dataset as the focal point of a data migration.
	For this reason, we define datasets first.

\subsection{Datasets}
	A dataset describes a set of structured data, which is typically stored persistently in a database of some kind.

	Before defining datasets, we must first define the constituent notions of atom, concept, triple, and relation.
	
	Atoms serve as data elements.
	They are values without internal structure of interest, meant to represent data elements in a database.
	From a business perspective, atoms are used to represent concrete items of the world,
	such as \atom{Peter}, \atom{1}, or \atom{the king of France}.
	By convention throughout the remainder of this paper, variables $a$, $b$, and $c$ are used to represent \emph{atoms}.
	The set of atoms is called $\atoms$.
	

	Concepts are names we use during the design of a dataset
	to name a group of atoms of the same type,
	to assign signatures to relations, and thus
	to enable type checking of the dataset.
	For example, you might choose to classify \atom{Peter} as a \concept{Person}, and \atom{074238991} as a \concept{TelephoneNumber}.
	In this example, \concept{Person} and \concept{TelephoneNumber} are concepts.
    We will use variables $A$, $B$, $C$, $D$ to represent concepts.
	The expression $a\ \inst\ A$ means that atom $a$ is an \emph{instance} of concept $A$.
	The statement $A\isa B$ (pronounce: $A$ is a $B$) states that any instance of $A$ is an instance of $B$ as well.
	We call this {\em specialization}, but it is also known as {\em generalization} or {\em subtyping}.
	Specialization is needed to allow statements such as: ``A woman is a human'' or ``A human is a mammal''.
	The set of concepts is called $\concepts$.
	
	Triples are used to represent data.
	This makes our theory valid for any kind of database that triples can represent,
	such as SQL databases, object-oriented databases, graph databases, triple stores, and other no-SQL databases
	Each triple relates two atoms to a relation.
	A triple $\triple{\text{\atom{Peter}}}{\id{phone}}{\text{\atom{074238991}}}$ might mean that the ``thing'' that \atom{Peter} refers to
	has \atom{074238991} as a telephone number.
	In the formal world, we leave it entirely up to a user to attach meaning to a triple.
	As a consequence, this ``meaning from practice'' may have no consequences in the formal world.
	The set of triples is called $\triples$.

	Relations in datasets are used to store data.
	In this paper relations are represented by variables $r$, $s$, and $d$.
	Every relation $r$ contains a set of pairs, which we call the population of $r$:
\begin{equation}
	\pop{r}\ =\ \{ \pair{a}{b}|\ \triple{a}{r}{b}\in\triples\}
\end{equation}
	The term $\ident{A}$ represents the \emph{identity relation} of concept $A$.

	Every relation has a name, a source concept, and a target concept.
	We write $\declare{nm}{A}{B}$ to denote a relation with name \id{nm}, source concept $A$, and target concept $B$.
	% To disassemble a relation in its name, source and target, there exist three functions:
% \[\begin{array}[3]{rcl}
	% \id{relname}&:&\rels\rightarrow\id{RelationIdentifier}\\
	% \id{src}&:&\rels\rightarrow\concepts\\
	% \id{tgt}&:&\rels\rightarrow\concepts
% \end{array}\]
	% Or, stated otherwise, the denotation $\declare{nm}{A}{B}$ stands for a relation with
	% \(\relname{\declare{nm}{A}{B}} = \id{nm}\),
	% \(\src{\declare{nm}{A}{B}}=A\), and
	% \(\tgt{\declare{nm}{A}{B}}=B\).

	The pair $\pair{A}{B}$ is called the \emph{signature} of the relation.
	The term $\fullt{A}{B}$ represents the \emph{universal relation} over concepts $A$ and $B$.
	It contains all pairs that can be made of elements of $A$ and $B$:
\[\pop{\fullt{A}{B}} = \{ \pair{a}{b}| a\ \inst\ A,\ b\ \inst\ B \}\]
	The term $\ident{A}$ represents the \emph{identity relation} over concept $A$.
	The set of relations is called $\rels$.
	
	We can now define the notion of dataset.
	Let	$\concepts$ be a set of concepts,
	let $\isa$ be a partial order on $\concepts$,
	let $\rels$ be a set of relations,
	let $\atoms$ be a set of atoms,
	and let $\inst$ be a relation $\atoms\times\concepts$ that represents the instance relation between concepts and atoms,
\begin{definition}[dataset]
	\label{def:dataset}
	\item A dataset is a tuple $\la\atoms,\concepts,\inst,\isa,\rels,\triples\ra$ with
	\begin{eqnarray}
		\forall a\in\atoms\ \exists A\in\concepts&:&a\ \inst\ A\\
		%\forall A,B\in\concepts, a\in\atoms&:&A\isa B\wedge a\ \inst\ A\ \Rightarrow\ a\ \inst\ B\\
		\forall \declare{n}{A}{B}\in\rels&:&A\in\concepts\ \wedge\ B\in\concepts\\
		\forall\triple{a}{\declare{n}{A}{B}}{b}\in\triples&:&\begin{array}[t]{@{}l}\declare{n}{A}{B}\in\rels\ \wedge\\ a\ (\inst \compose \kleenestar{\flip{\isa}})\ A\ \wedge\\ b\ (\inst \compose \kleenestar{\flip{\isa}})\ B\end{array}
	\end{eqnarray}
\end{definition}

\subsection{Information Systems}
\label{sct:Information Systems}
	The purpose of an information system is to make data meaningful to users.
	Data migration is all about preserving that meaning.
	So this section introduces the notion of information system
	as a system that consist of a dataset and a set constraints that users must keep satisfied.
	These constraints reflect the meaning that is shared by all users.

	Users have their own tasks and responsibilities
	and may work from different locations and on different moments.
	This collective use serves a purpose which we loosely call ``the business''.
	As a consequence, the data in an information system changes continually.
	To preserve meaning, users are trying to maintain semantic constraints on the data,
	amidst of all changes that are going on around them.
	So, let us first define the constituent notions role and constraint before defining information systems proper.

	A \define{role} is a name that identifies a group of users.
	The purpose of a role is to mention an individual user without knowing who that user is.
	In the sequel, when we talk about a role we actually mean a user (an arbitrary one) who fulfills that role in the information system.
	The set of roles is called $\roles$.

	A \define{constraint} is a restriction on a dataset, to be enforced by a role.
	The purpose of constraints is to ensure the semantics of a dataset, i.e. the preservation of meaning as data changes.
	Each constraint $u\in\rules$ has a signature $\signat{u}$, which is a pair of concepts.
	Each constraint $u$ also has a function $\id{viol}_u:\powerset{\atoms\times\rels\times\atoms}\ \rightarrow\ \powerset{\atoms\times\atoms}$.
	We call the set $\viol{\triples}{u}$ the \define{violation set} of constraint $u$ in population $\triples$.
	We call every element $\pair{a}{b}\in\viol{\triples}{u}$ a \define{violation} of constraint $u$ in $\triples$.
	We say that a constraint \define{is satisfied} if its violation set is empty.
	The set of constraints is called $\rules$.

	Note that the signature of $u$ does not depend on the population, whereas the violation set of $u$ may be different for every $\triples$.
	Since $\triples$ changes continually in an information system, the violations are changing along. 

	We can now define the notion of information system.
	Let $\roles$ be a set of roles,
	let $\rules$ be a set of constraints, 
	let $\maintain$ be a surjective relation $\roles\times\rules$,
	and let $\dataset$ be a dataset.
\begin{definition}[information system]
	\label{def:information system}
	\item An information system $\infsys$ is a tuple $\la\roles,\rules,\maintain,\dataset\ra$\\
	with dataset $\dataset=\la\atoms,\concepts,\inst,\isa,\rels,\triples\ra$
	in which $o\ \maintain\ u$ means that role $o$ must keep the set $\viol{\triples}{u}$ empty.
\end{definition}
	If a constraint $u$ has violations, i.e. $\viol{\triples}{u}$ is not empty, there is a role whose job it is to remove those violations.
	The relation $\maintain$ being surjective means that all users together are keeping the violation set empty.
	Which means that all constraints are being kept satisfied in the collective effort of users, even if the data changes.
	In another section we will give some options on how users can keep rules satisfied.

\subsection{Data migration}
	To migrate information system $\infsys$ to $\infsys'$, we take the disjoint union $\infsys\sqcup\infsys'$ of both information systems
	and add rules to describe the migration.
	$\infsys$ is the existing system, which contains data to be preserved.
	$\infsys'$ is the new system, which contains no or hardly any data.
	It does, however, contain the concepts, relations, rules and roles of the new system.
\begin{figure}[bht]
	\begin{center}
	  \includegraphics[scale=.45]{Migration.png}
	\end{center}
\caption{Data migration}
\label{fig:event flow}
\end{figure}
		
	We use two datasets: $\dataset=\la\atoms,\concepts,\inst,\isa,\rels,\triples\ra$ and $\dataset'=\la\atoms',\concepts',\inst',\isa',\rels',\triples'\ra$.
	Before doing so, let us first define the disjoint union of two information systems.
\begin{definition}[disjoint union of datasets]
	\begin{eqnarray}
		\dataset\sqcup\dataset'&=&\la\atoms\uplus\atoms',\ \concepts\uplus\concepts',\ \inst\uplus^2\inst',\ \isa\uplus^2\isa',\ \rels\uplus^3\rels',\ \triples\uplus^5\triples'\ra\\
		X\uplus Y&=&\{(x,0)|\ x\in X\}\ \cup\ \{(y,1)|\ y\in Y\}\\
		X\uplus^2 Y&=&\begin{array}[t]{@{}l}\{((x_1,0),(x_2,0))|\ (x_1,x_2)\in X\}\ \cup\\ \{((y_1,1),(y_2,1))|\ (y_1,y_2)\in Y\}\end{array}\\
		X\uplus^3 Y&=&\begin{array}[t]{@{}l}\{\declare{(n,0)}{(A,0)}{(B,0)}\mid\ \declare{n}{A}{B}\in X\}\ \cup\\ \{\declare{(n,1)}{(A,1)}{(B,1)}\mid\ \declare{n}{A}{B}\in Y\}\end{array}\\
		X\uplus^5 Y&=&\begin{array}[t]{@{}l}\{\triple{(a,0)}{\declare{(n,0)}{(A,0)}{(B,0)}}{(b,0)}\mid\ \declare{n}{A}{B}\in X\}\ \cup\\ \{\triple{(a,1)}{\declare{(n,1)}{(A,1)}{(B,1)}}{(b,1)}\mid\ \declare{n}{A}{B}\in Y\}\end{array}
	\end{eqnarray}
\end{definition}
Note that if $\dataset$ and $\dataset'$ are datasets, then so is $\dataset\sqcup\dataset'$.

\begin{definition}[migration dataset]
	\begin{eqnarray}
		&&\begin{array}[t]{@{}l}
			\{ {\tt ENFORCE\ }\declare{(nm',1)}{(A',1)}{(B',1)}\\\quad{\tt\ :=\ }\ident{(A',1)};\declare{(nm,0)}{(A,0)}{(B,0)};\ident{(B',1)}\\
				\mid\ \begin{array}[t]{@{}l}
					\declare{nm}{A}{B}\in\rels\wedge\declare{nm'}{A'}{B'}\in\rels'\wedge\id{nm}=\id{nm'}\ \wedge\\
					\{\pair{A}{A'},\pair{B}{B'}\}\subseteq\isa\cup\isa'\cup\flip{\isa}\cup\flip{\isa'}\}
				   \end{array}
			  \end{array}\\
			  &\cup&\begin{array}[t]{@{}l}
				\{ {\tt CLASSIFY\ }(C',1){\tt\ IS\ }(C,0)|\ C\in\concepts,C'\in\concepts',C=C'\}\\
			  \end{array}
	\end{eqnarray}
\end{definition}

The ${\tt CLASSIFY\ }(C',1){\tt\ IS\ }(C,0)$ statements add $((C',1),(C,0))$ and  $((C,0),(C',1))$ to the $\isa$ relation. Note that if $\dataset$ is a dataset, and $\dataset'$ is that dataset with pairs added\footnote{TODO: het woord `add' is informeel, dit kan beter} to the $\isa$ relation, then the result is again a dataset.
The ${\tt ENFORCE\ }r{\tt\ :=\ }e$ statements add triples $(x,r,y)$ for all $(x,y)\in e$.
The expressions $e$ in these statements are such that $x\ (\inst \compose \kleenestar{\flip{\isa}})\ (A',1)$ and $y \ (\inst \compose \kleenestar{\flip{\isa}})\ (B',1)$, thus preserving the property that the result is a dataset.

\begin{definition}[disjoint union of information systems]
	\begin{eqnarray}
		\infsys\sqcup\infsys'&=&\la\roles\uplus\roles',\rules\uplus^?\rules',\maintain\uplus^2\maintain',\dataset\sqcup\dataset'\ra
	\end{eqnarray}
\end{definition}

\subsection{Changes}
% The purpose of this section is to explain why a dataset is structured the way it is.
	In the migration of a dataset we deal with changes to the elements that are not data:
	$\isa$, $\inst$, $\concepts$, and $\rels$.
	Such changes have further reaching consequences, however.
	Changes to $\isa$, $\inst$, $\concepts$, $\rels$ change the data structure in a dataset.
	We define a \define{migration of a dataset} $\la\atoms,\concepts,\inst,\isa,\rels,\triples\ra$ as a change in which one or more of $\isa$, $\inst$, $\concepts$, or $\rels$ change.
	To satisfy definition~\ref{def:dataset}, $\triples$ and $\atoms$ must change too,
	but the migration should try to preserve the maximal amount of data.

	This paper studies those changes and seeks to preserve the rules in definition~\ref{def:dataset}
	in such a way that large portions of migration can be automated.


\section{Bibliography}
\bibliographystyle{elsarticle-harv}
\bibliography{doc}


\end{document}
